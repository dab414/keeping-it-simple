colnames(d)
## compute needed vars
d$difference3 <- d$difference^3
l1 <- glmer(transcode ~ difference + (1 + difference), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
l1 <- glmer(transcode ~ difference + (1 + difference | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
n1 <- glmer(transcode ~ difference + difference3 + (1 + difference + difference3 | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
## compute needed vars
d$difference_s <- scale(d$difference)
d$difference3 <- d$difference^3
l1 <- glmer(transcode ~ difference + (1 + difference | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
n1 <- glmer(transcode ~ difference + difference3 + (1 + difference + difference3 | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
l1 <- glmer(transcode ~ difference + (1 + difference | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
## model below with (1 + difference + difference3) random specification failed to converge
n1 <- glmer(transcode ~ difference + difference3 + (1 + difference | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
9^3
l1 <- glmer(transcode ~ difference + (1 + difference | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
## model below with (1 + difference + difference3) random specification failed to converge
n1 <- glmer(transcode ~ difference + scale(difference3) + (1 + difference + scale(difference3) | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
anova(l1, n1)
n2 <- glmer(transcode ~ difference + scale(difference3) + (1 | subject) + (0 + difference | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
anova(n1, n2)
n2 <- glmer(transcode ~ difference + scale(difference3) + (1 | subject) + (0 + difference | subject) + (0 + difference3), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
anova(n1, n2)
n2 <- glmer(transcode ~ difference + scale(difference3) + (1 | subject) + (0 + difference | subject) + (0 + difference3 | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
anova(n1, n2)
CIs <- confint(n1, method = 'boot')
q()
library(tidyverse)
library(lme4)
d <- read.csv('..//data/disconnect.csv')
d <- read.csv('../data/disconnect.csv')
d <- read.csv('../../data/disconnect.csv')
d
## compute needed vars
d$difference_s <- d$difference
d$difference3 <- d$difference^3
l1 <- glmer(transcode ~ difference + (1 + difference | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
n1 <- glmer(transcode ~ difference + scale(difference3) + (1 + difference + scale(difference3) | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
anova(l1, n1)
n2 <- glmer(transcode ~ difference + scale(difference3) + (1 | subject) + (0 + difference | subject) + (0 + difference3 | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
anova(n1, n2)
saveRDS(n2, 'models/n2.RData')
#n2 <- glmer(transcode ~ difference + scale(difference3) + (1 | subject) + (0 + difference | subject) + (0 + difference3 | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
saveRDS(n2, 'models/n2.RData')
anova(n1, n2)
#n2 <- glmer(transcode ~ difference + scale(difference3) + (1 | subject) + (0 + difference | subject) + (0 + difference3 | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
#saveRDS(n2, 'models/n2.RData')
load('models/n2.RData')
#n2 <- glmer(transcode ~ difference + scale(difference3) + (1 | subject) + (0 + difference | subject) + (0 + difference3 | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
#saveRDS(n2, 'models/n2.RData')
readRDS('models/n2.RData')
#l1 <- glmer(transcode ~ difference + (1 + difference | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
#n1 <- glmer(transcode ~ difference + scale(difference3) + (1 + difference + scale(difference3) | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
saveRDS(l1, n1, 'models/l1_n1.RData')
#l1 <- glmer(transcode ~ difference + (1 + difference | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
#n1 <- glmer(transcode ~ difference + scale(difference3) + (1 + difference + scale(difference3) | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
saveRDS(l1, n1, file = 'models/l1_n1.RData')
#l1 <- glmer(transcode ~ difference + (1 + difference | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
#n1 <- glmer(transcode ~ difference + scale(difference3) + (1 + difference + scale(difference3) | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
save(l1, n1, file = 'models/l1_n1.RData')
#l1 <- glmer(transcode ~ difference + (1 + difference | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
#n1 <- glmer(transcode ~ difference + scale(difference3) + (1 + difference + scale(difference3) | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
#save(l1, n1, file = 'models/l1_n1.RData')
load('models/li_n1.RData')
#l1 <- glmer(transcode ~ difference + (1 + difference | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
#n1 <- glmer(transcode ~ difference + scale(difference3) + (1 + difference + scale(difference3) | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
#save(l1, n1, file = 'models/l1_n1.RData')
load('models/l1_n1.RData')
anova(l1, n1)
## takes too long
CIs <- confint(n1, method = 'wald')
## takes too long
CIs <- confint(n1, method = 'Wald')
CIs
summary(n1)
exp(fixef(n1))
## takes too long
CIs <- confint(n1, method = 'Wald')
CIs
exp(CIs)
summary(n1)
exp(fixef(n1))
## takes too long
CIs <- confint(n1, method = 'Wald')
exp(CIs)
n1_no3 <- glmer(transcode ~ difference + (1 + difference + scale(difference3) | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
anova(n1, n1_no3)
#n1_no3 <- glmer(transcode ~ difference + (1 + difference + scale(difference3) | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
saveRDS(n1_no3, 'models/n1_no3.RData')
#n1_no3 <- glmer(transcode ~ difference + (1 + difference + scale(difference3) | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
#saveRDS(n1_no3, 'models/n1_no3.RData')
loadRds('models/n1_no3.RData')
#n1_no3 <- glmer(transcode ~ difference + (1 + difference + scale(difference3) | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
#saveRDS(n1_no3, 'models/n1_no3.RData')
loadRDS('models/n1_no3.RData')
#n1_no3 <- glmer(transcode ~ difference + (1 + difference + scale(difference3) | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
#saveRDS(n1_no3, 'models/n1_no3.RData')
readRDS('models/n1_no3.RData')
anova(n1, n1_no3)
rm(n1_no3)
#n1_no3 <- glmer(transcode ~ difference + (1 + difference + scale(difference3) | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
#saveRDS(n1_no3, 'models/n1_no3.RData')
readRDS('models/n1_no3.RData')
#n1_no3 <- glmer(transcode ~ difference + (1 + difference + scale(difference3) | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
#saveRDS(n1_no3, 'models/n1_no3.RData')
readRDS('models/n1_no3.RData')
anova(n1, n1_no3)
rm(n1)
#l1 <- glmer(transcode ~ difference + (1 + difference | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
#n1 <- glmer(transcode ~ difference + scale(difference3) + (1 + difference + scale(difference3) | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
#save(l1, n1, file = 'models/l1_n1.RData')
load('models/l1_n1.RData')
anova(l1, n1)
#n1_no3 <- glmer(transcode ~ difference + (1 + difference + scale(difference3) | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
#saveRDS(n1_no3, 'models/n1_no3.RData')
n1_no3 <- readRDS('models/n1_no3.RData')
anova(n1, n1_no3)
n1_nod <- glmer(transcode ~ difference3 + (1 + difference + scale(difference3) | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
saveRDS(n1_nod, 'models/n1_nod')
n1_nod <- readRDS('models/n1_nod')
anova(n1, n1_nod)
n1_nod <- glmer(transcode ~ scale(difference3) + (1 + difference + scale(difference3) | subject), data = d, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'))
saveRDS(n1_nod, 'models/n1_nod')
n1_nod <- readRDS('models/n1_nod')
anova(n1, n1_nod)
newdata <- data.frame(difference = -9:9)
newdata$difference3 = scale(newdata$difference)
newdata$proba <- predict(n1, newdata = newdata, type = 'response')
newdata$proba <- predict(n1, newdata = newdata, type = 'response', allow.new.levels = TRUE, re.form = NA)
head(newdata)
newdata <- cbind(newdata, easyPredCI(n1, newdata = newdata))
### bolker's compute CI function
easyPredCI <- function(model,newdata=NULL,alpha=0.05) {
## baseline prediction, on the linear predictor (logit) scale:
pred0 <- predict(model,re.form=NA,newdata=newdata)
## fixed-effects model matrix for new data
X <- model.matrix(formula(model,fixed.only=TRUE)[-2],newdata)
beta <- fixef(model) ## fixed-effects coefficients
V <- vcov(model)     ## variance-covariance matrix of beta
pred.se <- sqrt(diag(X %*% V %*% t(X))) ## std errors of predictions
## inverse-link function
linkinv <- family(model)$linkinv
## construct 95% Normal CIs on the link scale and
##  transform back to the response (probability) scale:
crit <- -qnorm(alpha/2)
linkinv(cbind(conf.low=pred0-crit*pred.se,
conf.high=pred0+crit*pred.se))
}
newdata <- cbind(newdata, easyPredCI(n1, newdata = newdata))
newdata
d %>%
group_by(subject, difference) %>%
summarize(switch = mean(transcode)) %>%
ggplot(aes(x = difference, y = switch)) +
geom_line(aes(group = subject)) +
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .4, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba), color = 'blue', size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
theme_minimal()
d %>%
group_by(subject, difference) %>%
summarize(switch = mean(transcode)) %>%
head()
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference, y = transcode)) +
geom_line(aes(group = subject)) +
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .4, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba), color = 'blue', size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
theme_minimal()
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
head()
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
tail()
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference, y = transcode)) +
geom_line(aes(group = subject)) +
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .4, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba), color = 'blue', size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
theme_minimal()
library(tidyverse)
library(lme4)
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference, y = transcode)) +
geom_line(aes(group = subject)) +
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .4, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba), color = 'blue', size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
theme_minimal()
head(d)
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference, y = transcode)) +
geom_line(aes(group = subject))
#geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .4, fill = 'blue') +
#geom_line(data = newdata, aes(x = difference, y = proba), color = 'blue', size = 2) +
#labs(
#x = 'Points for Switching Tasks',
# y = 'Proportion of Task Switching'
#) +
#theme_minimal()
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference, y = transcode)) +
geom_line(aes(group = subject))
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high, y = proba), alpha = .4, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba), color = 'blue', size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
theme_minimal()
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference)) +
geom_line(aes(group = subject, y = transcode))
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .4, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba), color = 'blue', size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
theme_minimal()
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference)) +
geom_line(aes(group = subject, y = transcode)) +
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .4, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba), color = 'blue', size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
theme_minimal()
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference)) +
geom_line(aes(group = subject, y = transcode)) +
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .4, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba), color = 'blue', size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
scale_x_manual(labels = -9:9, breaks = -9:9) +
theme_minimal()
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference)) +
geom_line(aes(group = subject, y = transcode)) +
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .4, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba), color = 'blue', size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
scale_x_continuous(labels = -9:9, breaks = -9:9) +
theme_minimal()
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference)) +
geom_line(aes(group = subject, y = transcode)) +
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .4, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba), color = 'blue', size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
scale_x_continuous(labels = -9:9, breaks = -9:9) +
theme_minimal() +
theme(panel.grid = element_blank(),
panel.border = element_rect(fill = NA, color = 'black'))
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference)) +
geom_line(aes(group = subject, y = transcode, color = 'black')) +
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .4, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba, color = 'blue'), size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
scale_x_continuous(labels = -9:9, breaks = -9:9) +
theme_minimal() +
theme(panel.grid = element_blank(),
panel.border = element_rect(fill = NA, color = 'black'))
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference)) +
geom_line(aes(group = subject, y = transcode, color = 'black')) +
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .4, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba, color = 'blue'), size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
scale_x_continuous(labels = -9:9, breaks = -9:9) +
scale_color_manual(values = c('black' = 'black', 'blue' = 'blue'), labels = c('black' = 'Subject Means', 'Blue' = 'Model Prediction')) +
theme_minimal() +
theme(panel.grid = element_blank(),
panel.border = element_rect(fill = NA, color = 'black'))
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference)) +
geom_line(aes(group = subject, y = transcode, color = 'black')) +
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .4, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba, color = 'blue'), size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
scale_x_continuous(labels = -9:9, breaks = -9:9) +
scale_color_manual(values = c('black' = 'black', 'blue' = 'blue'), labels = c('black' = 'Subject Means', 'blue' = 'Model Prediction')) +
theme_minimal() +
theme(panel.grid = element_blank(),
panel.border = element_rect(fill = NA, color = 'black'))
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference)) +
geom_line(aes(group = subject, y = transcode, color = 'black')) +
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .4, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba, color = 'blue'), size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
scale_x_continuous(labels = -9:9, breaks = -9:9) +
scale_color_manual(values = c('black' = 'black', 'blue' = 'blue'), labels = c('black' = 'Subject Means', 'blue' = 'Model Prediction'), name = element_blank()) +
theme_minimal() +
theme(panel.grid = element_blank(),
panel.border = element_rect(fill = NA, color = 'black'))
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference)) +
geom_line(aes(group = subject, y = transcode, color = 'black')) +
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .4, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba, color = 'blue'), size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
scale_x_continuous(labels = -9:9, breaks = -9:9) +
scale_color_manual(values = c('black' = 'black', 'blue' = 'blue'), labels = c('black' = 'Subject Means', 'blue' = 'Model Prediction'), name = element_blank()) +
theme_minimal() +
theme(panel.grid = element_blank(),
panel.border = element_rect(fill = NA, color = 'black'),
legend.position = c(-6, .75))
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference)) +
geom_line(aes(group = subject, y = transcode, color = 'black')) +
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .4, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba, color = 'blue'), size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
scale_x_continuous(labels = -9:9, breaks = -9:9) +
scale_color_manual(values = c('black' = 'black', 'blue' = 'blue'), labels = c('black' = 'Subject Means', 'blue' = 'Model Prediction'), name = element_blank()) +
theme_minimal() +
theme(panel.grid = element_blank(),
panel.border = element_rect(fill = NA, color = 'black'),
legend.position = c(-1, .75))
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference)) +
geom_line(aes(group = subject, y = transcode, color = 'black')) +
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .4, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba, color = 'blue'), size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
scale_x_continuous(labels = -9:9, breaks = -9:9) +
scale_color_manual(values = c('black' = 'black', 'blue' = 'blue'), labels = c('black' = 'Subject Means', 'blue' = 'Model Prediction'), name = element_blank()) +
theme_minimal() +
theme(panel.grid = element_blank(),
panel.border = element_rect(fill = NA, color = 'black'),
legend.position = c(1, .75))
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference)) +
geom_line(aes(group = subject, y = transcode, color = 'black')) +
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .4, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba, color = 'blue'), size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
scale_x_continuous(labels = -9:9, breaks = -9:9) +
scale_color_manual(values = c('black' = 'black', 'blue' = 'blue'), labels = c('black' = 'Subject Means', 'blue' = 'Model Prediction'), name = element_blank()) +
theme_minimal() +
theme(panel.grid = element_blank(),
panel.border = element_rect(fill = NA, color = 'black'),
legend.position = c(.25, .75))
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference)) +
geom_line(aes(group = subject, y = transcode, color = 'black')) +
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .4, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba, color = 'blue'), size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
scale_x_continuous(labels = -9:9, breaks = -9:9) +
scale_color_manual(values = c('black' = 'black', 'blue' = 'blue'), labels = c('black' = 'Subject Means', 'blue' = 'Model Prediction'), name = element_blank()) +
theme_minimal() +
theme(panel.grid = element_blank(),
panel.border = element_rect(fill = NA, color = 'black'),
legend.position = c(.2, .75))
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference)) +
geom_line(aes(group = subject, y = transcode, color = 'black')) +
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .3, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba, color = 'blue'), size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
scale_x_continuous(labels = -9:9, breaks = -9:9) +
scale_color_manual(values = c('black' = 'black', 'blue' = 'blue'), labels = c('black' = 'Subject Means', 'blue' = 'Model Prediction'), name = element_blank()) +
theme_minimal() +
theme(panel.grid = element_blank(),
panel.border = element_rect(fill = NA, color = 'black'),
legend.position = c(.2, .75))
pos <- d[d$difference > 0,]
l1_pos <- glmer(transcode ~ difference + (1 + difference | subject), data = pos, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'), nAGQ = 1)
l1_pos_nocov <- glmer(transcode ~ difference + (1 | subject) + (0 + difference | subject), data = pos, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'), nAGQ = 1)
save(l1_pos, l1_pos_nocov, file = 'models/l1_pos.RData')
load(l1_pos, 'models/l1_pos.RData')
load(l1_pos, file = 'models/l1_pos.RData')
load(file = 'models/l1_pos.RData')
anova(l1_pos, l1_pos_nocov)
summary(l1_pos)
exp(fixef(l1_pos))
confint(l1_pos, method = 'Wald')
summary(l1_pos)
exp(fixef(l1_pos))
exp(confint(l1_pos, method = 'Wald'))
li_pos_nodiff <- glmer(transcode ~ 1 + (1 + difference | subject), data = pos, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'), nAGQ = 1)
saveRDS(li_pos_nodiff, 'models/li_pos_nodiff')
li_pos_nodiff <- readRDS('models/li_pos_nodiff')
anova(l1_pos, l1_pos_nodiff)
l1_pos_nodiff <- glmer(transcode ~ 1 + (1 + difference | subject), data = pos, family = binomial(link = 'logit'), control = glmerControl(optimizer = 'bobyqa'), nAGQ = 1)
saveRDS(l1_pos_nodiff, 'models/l1_pos_nodiff')
l1_pos_nodiff <- readRDS('models/l1_pos_nodiff')
anova(l1_pos, l1_pos_nodiff)
ggsave('cubic_glmer_prediction.png', height = 3.5, width = 5.5, units = 'in')
d %>%
group_by(subject, difference) %>%
summarize(transcode = mean(transcode)) %>%
ggplot(aes(x = difference)) +
geom_line(aes(group = subject, y = transcode, color = 'black')) +
geom_ribbon(data = newdata, aes(ymin = conf.low, ymax = conf.high), alpha = .3, fill = 'blue') +
geom_line(data = newdata, aes(x = difference, y = proba, color = 'blue'), size = 2) +
labs(
x = 'Points for Switching Tasks',
y = 'Proportion of Task Switching'
) +
scale_x_continuous(labels = -9:9, breaks = -9:9) +
scale_color_manual(values = c('black' = 'black', 'blue' = 'blue'), labels = c('black' = 'Subject Means', 'blue' = 'Model Prediction'), name = element_blank()) +
theme_minimal() +
theme(panel.grid = element_blank(),
panel.border = element_rect(fill = NA, color = 'black'),
legend.position = c(.2, .75))
ggsave('cubic_glmer_prediction.png', height = 3.5, width = 5.5, units = 'in')
ggsave('cubic_glmer_prediction.png', height = 5.5, width = 7.5, units = 'in')
q()
q()
q()
